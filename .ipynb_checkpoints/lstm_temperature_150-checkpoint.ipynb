{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Lambda\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84692\n"
     ]
    }
   ],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "all_text = open(\"data/shakespeare.txt\").read().lower()\n",
    "all_text = ''.join([i for i in all_text if not i.isdigit()])\n",
    "SYMBOL_LIST = {'?', '.',  ')', ',', '!', ';', '(', ':'}\n",
    "sonnets = all_text.replace('                   ', '').split('\\n\\n\\n')\n",
    "sonnets = [sonnet[1:] for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('\\n', ' ') for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('  ', '') for sonnet in sonnets]\n",
    "sonnets = [''.join([i for i in sonnet if not i in SYMBOL_LIST]) for sonnet in sonnets]\n",
    "\n",
    "all_chars = sorted(list(set(''.join(sonnets))))\n",
    "max_char = len(all_chars) - 1\n",
    "char_map = {}\n",
    "int_to_char = {}\n",
    "int_to_arr = {}\n",
    "for i in range(len(all_chars)):\n",
    "    char_map[all_chars[i]] = i\n",
    "    int_to_char[i] = all_chars[i]\n",
    "    arr = [0] * len(all_chars) \n",
    "    arr[i] = 1\n",
    "    int_to_arr[i] = arr\n",
    "\n",
    "# print(sonnets)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for sonnet in sonnets:\n",
    "    start = 0\n",
    "    end = 40\n",
    "    while end < len(sonnet):\n",
    "        sequence = sonnet[start:end]\n",
    "        X_train.append([(char_map[c]) for c in sequence])\n",
    "        Y_train.append(char_map[sonnet[end]])\n",
    "        start += 1\n",
    "        end += 1\n",
    "        \n",
    "samples = len(X_train)\n",
    "timesteps = 40\n",
    "features = len(all_chars)\n",
    "X_train = [[int_to_arr[x] for x in seq] for seq in X_train]\n",
    "\n",
    "X_train = np.array(X_train) \n",
    "X_train = np.reshape(X_train, (samples, timesteps, features))\n",
    "Y_train = np.array([int_to_arr[y] for y in Y_train])\n",
    "\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84692/84692 [==============================] - 384s 5ms/step - loss: 2.5535\n",
      "Epoch 2/50\n",
      "84692/84692 [==============================] - 371s 4ms/step - loss: 2.0975\n",
      "Epoch 3/50\n",
      "84692/84692 [==============================] - 371s 4ms/step - loss: 1.9407\n",
      "Epoch 4/50\n",
      "84692/84692 [==============================] - 363s 4ms/step - loss: 1.8499\n",
      "Epoch 5/50\n",
      "84692/84692 [==============================] - 383s 5ms/step - loss: 1.7810\n",
      "Epoch 6/50\n",
      "84692/84692 [==============================] - 405s 5ms/step - loss: 1.7275\n",
      "Epoch 7/50\n",
      "84692/84692 [==============================] - 417s 5ms/step - loss: 1.6838\n",
      "Epoch 8/50\n",
      "84692/84692 [==============================] - 408s 5ms/step - loss: 1.6452\n",
      "Epoch 9/50\n",
      "84692/84692 [==============================] - 347s 4ms/step - loss: 1.6177\n",
      "Epoch 10/50\n",
      "84692/84692 [==============================] - 346s 4ms/step - loss: 1.5875\n",
      "Epoch 11/50\n",
      "84692/84692 [==============================] - 347s 4ms/step - loss: 1.5997\n",
      "Epoch 12/50\n",
      "84692/84692 [==============================] - 350s 4ms/step - loss: 1.8102\n",
      "Epoch 13/50\n",
      "84692/84692 [==============================] - 390s 5ms/step - loss: 1.8709\n",
      "Epoch 14/50\n",
      "84692/84692 [==============================] - 381s 4ms/step - loss: 1.7345\n",
      "Epoch 15/50\n",
      "84692/84692 [==============================] - 388s 5ms/step - loss: 1.6890\n",
      "Epoch 16/50\n",
      "84692/84692 [==============================] - 367s 4ms/step - loss: 1.6971\n",
      "Epoch 17/50\n",
      "84692/84692 [==============================] - 353s 4ms/step - loss: 1.6574\n",
      "Epoch 18/50\n",
      "84692/84692 [==============================] - 352s 4ms/step - loss: 1.6112\n",
      "Epoch 19/50\n",
      "84692/84692 [==============================] - 350s 4ms/step - loss: 1.5876\n",
      "Epoch 20/50\n",
      "84692/84692 [==============================] - 344s 4ms/step - loss: 1.6520\n",
      "Epoch 21/50\n",
      "84692/84692 [==============================] - 2461s 29ms/step - loss: 1.6129\n",
      "Epoch 22/50\n",
      "84692/84692 [==============================] - 352s 4ms/step - loss: 1.5799\n",
      "Epoch 23/50\n",
      "84692/84692 [==============================] - 349s 4ms/step - loss: 1.5852\n",
      "Epoch 24/50\n",
      "84692/84692 [==============================] - 352s 4ms/step - loss: 1.5798\n",
      "Epoch 25/50\n",
      "84692/84692 [==============================] - 349s 4ms/step - loss: 1.5593\n",
      "Epoch 26/50\n",
      "84692/84692 [==============================] - 346s 4ms/step - loss: 1.5369\n",
      "Epoch 27/50\n",
      "84692/84692 [==============================] - 6577s 78ms/step - loss: 1.5156\n",
      "Epoch 28/50\n",
      "84692/84692 [==============================] - 385s 5ms/step - loss: 1.4984\n",
      "Epoch 29/50\n",
      "84692/84692 [==============================] - 383s 5ms/step - loss: 1.4772\n",
      "Epoch 30/50\n",
      "84692/84692 [==============================] - 390s 5ms/step - loss: 1.4589\n",
      "Epoch 31/50\n",
      "84692/84692 [==============================] - 419s 5ms/step - loss: 1.4449\n",
      "Epoch 32/50\n",
      "84692/84692 [==============================] - 468s 6ms/step - loss: 1.4287\n",
      "Epoch 33/50\n",
      "84692/84692 [==============================] - 386s 5ms/step - loss: 1.4133\n",
      "Epoch 34/50\n",
      "84692/84692 [==============================] - 359s 4ms/step - loss: 1.4170\n",
      "Epoch 35/50\n",
      "84692/84692 [==============================] - 353s 4ms/step - loss: 1.3869\n",
      "Epoch 36/50\n",
      "84692/84692 [==============================] - 354s 4ms/step - loss: 1.3668\n",
      "Epoch 37/50\n",
      "84692/84692 [==============================] - 353s 4ms/step - loss: 1.3513\n",
      "Epoch 38/50\n",
      "84692/84692 [==============================] - 350s 4ms/step - loss: 1.3411\n",
      "Epoch 39/50\n",
      "84692/84692 [==============================] - 347s 4ms/step - loss: 1.3327\n",
      "Epoch 40/50\n",
      "84692/84692 [==============================] - 16108s 190ms/step - loss: 1.3244\n",
      "Epoch 41/50\n",
      "84692/84692 [==============================] - 442s 5ms/step - loss: 1.3305\n",
      "Epoch 42/50\n",
      "84692/84692 [==============================] - 381s 5ms/step - loss: 1.3123\n",
      "Epoch 43/50\n",
      "84692/84692 [==============================] - 360s 4ms/step - loss: 1.2968\n",
      "Epoch 44/50\n",
      "84692/84692 [==============================] - 376s 4ms/step - loss: 1.2857\n",
      "Epoch 45/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.2799\n",
      "Epoch 46/50\n",
      "84692/84692 [==============================] - 353s 4ms/step - loss: 1.2693\n",
      "Epoch 47/50\n",
      "84692/84692 [==============================] - 356s 4ms/step - loss: 1.2595\n",
      "Epoch 48/50\n",
      "84692/84692 [==============================] - 355s 4ms/step - loss: 1.2491\n",
      "Epoch 49/50\n",
      "84692/84692 [==============================] - 354s 4ms/step - loss: 1.2417\n",
      "Epoch 50/50\n",
      "84692/84692 [==============================] - 355s 4ms/step - loss: 1.2324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2270f762ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Layers:\n",
    "temp = 1.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(timesteps, features), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Lambda(lambda x: x / temp))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=128)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day then therefore to lines sur or writeled wonds o'er all more side a wink end horse canst find hath that postry diserfect his churl o namo and hate he shrift do i am moy i queint against he will refounded and me thought do not plove's are to what it thy might i am gone shadow my heart canliwn do that love that say it king to never being end of my forroned filded the world or summer's fool with he i with the hulber in thine he toun and unon ture but happiel no mine and tender it my falfered in thy joan kings to me more till yet live in their own self so thy worth that brook honour once with untented out then since speak all it grace i to gues thine gone but love o that is blow th' with all my might my love's comprended once abistance came muse nothing none so long it that in what feights to other and sproight desire seen with no hole thy true love they for thy bud then i sum alone made of you to day then it so should most part with my love's fickle quill stand alone be'ate when thou thy be\n"
     ]
    }
   ],
   "source": [
    "def next_char(input_str, m):\n",
    "    X_in = np.array([[int_to_arr[char_map[c]] for c in input_str]])\n",
    "    [probs] = m.predict(X_in, verbose=0)\n",
    "    options = list(range(len(probs)))\n",
    "\n",
    "    \n",
    "    prediction = np.random.choice(options,p =  probs)\n",
    "    \n",
    "    return int_to_char[prediction]\n",
    "\n",
    "result = \"shall i compare thee to a summer's day t\"\n",
    "window = \"shall i compare thee to a summer's day t\"\n",
    "for i in range(1000):\n",
    "    prediction = next_char(window, model)\n",
    "    result = result + prediction\n",
    "    window = window[1:] + prediction\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_poem(t, words_per_line, num_lines):\n",
    "    result = []\n",
    "\n",
    "    start = 0\n",
    "    end = -1\n",
    "    space_count = 0\n",
    "\n",
    "    for i in range(len(t)):\n",
    "        end += 1\n",
    "        if t[i] == ' ':\n",
    "            space_count += 1\n",
    "        if space_count > words_per_line - 1:\n",
    "            result.append(t[start:end])\n",
    "            start = end + 1\n",
    "            space_count = 0\n",
    "        if i == len(t) - 1:\n",
    "            result.append(t[start: end + 1])\n",
    "        if len(result) == num_lines:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day,\n",
      "then therefore to lines sur or writeled wonds.\n",
      "o'er all more side a wink end horse,\n",
      "canst find hath that postry diserfect his churl.\n",
      "o namo and hate he shrift do i,\n",
      "am moy i queint against he will refounded.\n",
      "and me thought do not plove's are to,\n",
      "what it thy might i am gone shadow.\n",
      "my heart canliwn do that love that say,\n",
      "it king to never being end of my.\n"
     ]
    }
   ],
   "source": [
    "poem = get_poem(result, 8, 10)\n",
    "for i in range(len(poem)):\n",
    "    if i % 2 == 0:\n",
    "        print(poem[i] + ',')\n",
    "    else:\n",
    "        print(poem[i] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
