{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Lambda\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84692\n"
     ]
    }
   ],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "all_text = open(\"data/shakespeare.txt\").read().lower()\n",
    "all_text = ''.join([i for i in all_text if not i.isdigit()])\n",
    "SYMBOL_LIST = {'?', '.',  ')', ',', '!', ';', '(', ':'}\n",
    "sonnets = all_text.replace('                   ', '').split('\\n\\n\\n')\n",
    "sonnets = [sonnet[1:] for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('\\n', ' ') for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('  ', '') for sonnet in sonnets]\n",
    "sonnets = [''.join([i for i in sonnet if not i in SYMBOL_LIST]) for sonnet in sonnets]\n",
    "\n",
    "all_chars = sorted(list(set(''.join(sonnets))))\n",
    "max_char = len(all_chars) - 1\n",
    "char_map = {}\n",
    "int_to_char = {}\n",
    "int_to_arr = {}\n",
    "for i in range(len(all_chars)):\n",
    "    char_map[all_chars[i]] = i\n",
    "    int_to_char[i] = all_chars[i]\n",
    "    arr = [0] * len(all_chars) \n",
    "    arr[i] = 1\n",
    "    int_to_arr[i] = arr\n",
    "\n",
    "# print(sonnets)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for sonnet in sonnets:\n",
    "    start = 0\n",
    "    end = 40\n",
    "    while end < len(sonnet):\n",
    "        sequence = sonnet[start:end]\n",
    "        X_train.append([(char_map[c]) for c in sequence])\n",
    "        Y_train.append(char_map[sonnet[end]])\n",
    "        start += 1\n",
    "        end += 1\n",
    "        \n",
    "samples = len(X_train)\n",
    "timesteps = 40\n",
    "features = len(all_chars)\n",
    "X_train = [[int_to_arr[x] for x in seq] for seq in X_train]\n",
    "\n",
    "X_train = np.array(X_train) \n",
    "X_train = np.reshape(X_train, (samples, timesteps, features))\n",
    "Y_train = np.array([int_to_arr[y] for y in Y_train])\n",
    "\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84692/84692 [==============================] - 474s 6ms/step - loss: 2.3938\n",
      "Epoch 2/50\n",
      "84692/84692 [==============================] - 461s 5ms/step - loss: 1.9232\n",
      "Epoch 3/50\n",
      "84692/84692 [==============================] - 455s 5ms/step - loss: 1.7762\n",
      "Epoch 4/50\n",
      "84692/84692 [==============================] - 7632s 90ms/step - loss: 1.6854\n",
      "Epoch 5/50\n",
      "84692/84692 [==============================] - 20316s 240ms/step - loss: 1.6196\n",
      "Epoch 6/50\n",
      "84692/84692 [==============================] - 544s 6ms/step - loss: 1.5626\n",
      "Epoch 7/50\n",
      "84692/84692 [==============================] - 566s 7ms/step - loss: 1.5151\n",
      "Epoch 8/50\n",
      "84692/84692 [==============================] - 2560s 30ms/step - loss: 1.4705\n",
      "Epoch 9/50\n",
      "84692/84692 [==============================] - 446s 5ms/step - loss: 1.4274\n",
      "Epoch 10/50\n",
      "84692/84692 [==============================] - 433s 5ms/step - loss: 1.3877\n",
      "Epoch 11/50\n",
      "84692/84692 [==============================] - 430s 5ms/step - loss: 1.3522\n",
      "Epoch 12/50\n",
      "84692/84692 [==============================] - 503s 6ms/step - loss: 1.3124\n",
      "Epoch 13/50\n",
      "84692/84692 [==============================] - 514s 6ms/step - loss: 1.2745\n",
      "Epoch 14/50\n",
      "84692/84692 [==============================] - 463s 5ms/step - loss: 1.2340\n",
      "Epoch 15/50\n",
      "84692/84692 [==============================] - 492s 6ms/step - loss: 1.1963\n",
      "Epoch 16/50\n",
      "84692/84692 [==============================] - 534s 6ms/step - loss: 1.1573\n",
      "Epoch 17/50\n",
      "84692/84692 [==============================] - 486s 6ms/step - loss: 1.1177\n",
      "Epoch 18/50\n",
      "84692/84692 [==============================] - 516s 6ms/step - loss: 1.0834\n",
      "Epoch 19/50\n",
      "84692/84692 [==============================] - 511s 6ms/step - loss: 1.0454\n",
      "Epoch 20/50\n",
      "84692/84692 [==============================] - 513s 6ms/step - loss: 1.0119\n",
      "Epoch 21/50\n",
      "84692/84692 [==============================] - 519s 6ms/step - loss: 0.9735\n",
      "Epoch 22/50\n",
      "84692/84692 [==============================] - 544s 6ms/step - loss: 0.9446\n",
      "Epoch 23/50\n",
      "84692/84692 [==============================] - 532s 6ms/step - loss: 0.9125\n",
      "Epoch 24/50\n",
      "84692/84692 [==============================] - 496s 6ms/step - loss: 0.8821\n",
      "Epoch 25/50\n",
      "84692/84692 [==============================] - 485s 6ms/step - loss: 0.8569\n",
      "Epoch 26/50\n",
      "84692/84692 [==============================] - 593s 7ms/step - loss: 0.8307\n",
      "Epoch 27/50\n",
      "84692/84692 [==============================] - 496s 6ms/step - loss: 0.8031\n",
      "Epoch 28/50\n",
      "84692/84692 [==============================] - 434s 5ms/step - loss: 0.7821\n",
      "Epoch 29/50\n",
      "84692/84692 [==============================] - 433s 5ms/step - loss: 0.7574\n",
      "Epoch 30/50\n",
      "84692/84692 [==============================] - 437s 5ms/step - loss: 0.7381\n",
      "Epoch 31/50\n",
      "84692/84692 [==============================] - 436s 5ms/step - loss: 0.7168\n",
      "Epoch 32/50\n",
      "84692/84692 [==============================] - 439s 5ms/step - loss: 0.6961\n",
      "Epoch 33/50\n",
      "84692/84692 [==============================] - 434s 5ms/step - loss: 0.6815\n",
      "Epoch 34/50\n",
      "84692/84692 [==============================] - 444s 5ms/step - loss: 0.6652\n",
      "Epoch 35/50\n",
      "84692/84692 [==============================] - 470s 6ms/step - loss: 0.6477\n",
      "Epoch 36/50\n",
      "84692/84692 [==============================] - 436s 5ms/step - loss: 0.6359\n",
      "Epoch 37/50\n",
      "84692/84692 [==============================] - 433s 5ms/step - loss: 0.6215\n",
      "Epoch 38/50\n",
      "84692/84692 [==============================] - 448s 5ms/step - loss: 0.6115\n",
      "Epoch 39/50\n",
      "84692/84692 [==============================] - 428s 5ms/step - loss: 0.5945\n",
      "Epoch 40/50\n",
      "84692/84692 [==============================] - 539s 6ms/step - loss: 0.5845\n",
      "Epoch 41/50\n",
      "84692/84692 [==============================] - 486s 6ms/step - loss: 0.5794\n",
      "Epoch 42/50\n",
      "84692/84692 [==============================] - 538s 6ms/step - loss: 0.5646\n",
      "Epoch 43/50\n",
      "84692/84692 [==============================] - 498s 6ms/step - loss: 0.5543\n",
      "Epoch 44/50\n",
      "84692/84692 [==============================] - 513s 6ms/step - loss: 0.5454\n",
      "Epoch 45/50\n",
      "84692/84692 [==============================] - 516s 6ms/step - loss: 0.5331\n",
      "Epoch 46/50\n",
      "84692/84692 [==============================] - 516s 6ms/step - loss: 0.5289\n",
      "Epoch 47/50\n",
      "84692/84692 [==============================] - 509s 6ms/step - loss: 0.5200\n",
      "Epoch 48/50\n",
      "84692/84692 [==============================] - 502s 6ms/step - loss: 0.5136\n",
      "Epoch 49/50\n",
      "84692/84692 [==============================] - 494s 6ms/step - loss: 0.5076\n",
      "Epoch 50/50\n",
      "84692/84692 [==============================] - 437s 5ms/step - loss: 0.4945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a88d5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Layers:\n",
    "temp = 0.75\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(timesteps, features), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Lambda(lambda x: x / temp))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day thou art more lovely apry death's better sight sees beautious not so should look in at me so ilike of you to be and do i foul that your self alone the is but since his now so ruch as end i gain and pleased my love be forgettent her o better dost and all blink name but now to fear as blinh so defence the fairest grow and so rellyer stell letp your true love can yet in thy countent trues such counterfouge to have i you so was thy feal that with which on pen cereshed o themseff the realth used with thee all of heart for enoued but from my boddy beauty is setser still to me that upon tay my name for thy robe for there and therefore i never was to my becomest of my had makes hell and idhe sense when faloused with thy sof out a grow inderies the good a for o thure on my so stake all some to calls now up as this to do i not see nor dest ride with others in that for thy worst i thing on my love or ment when thou fresh reparred in and more bright and happy how deared have in thee that much his p\n"
     ]
    }
   ],
   "source": [
    "def next_char(input_str, m):\n",
    "    X_in = np.array([[int_to_arr[char_map[c]] for c in input_str]])\n",
    "    [probs] = m.predict(X_in, verbose=0)\n",
    "    options = list(range(len(probs)))\n",
    "\n",
    "    \n",
    "    prediction = np.random.choice(options,p =  probs)\n",
    "    \n",
    "    return int_to_char[prediction]\n",
    "\n",
    "result = \"shall i compare thee to a summer's day t\"\n",
    "window = \"shall i compare thee to a summer's day t\"\n",
    "for i in range(1000):\n",
    "    prediction = next_char(window, model)\n",
    "    result = result + prediction\n",
    "    window = window[1:] + prediction\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_poem(t, words_per_line, num_lines):\n",
    "    result = []\n",
    "\n",
    "    start = 0\n",
    "    end = -1\n",
    "    space_count = 0\n",
    "\n",
    "    for i in range(len(t)):\n",
    "        end += 1\n",
    "        if t[i] == ' ':\n",
    "            space_count += 1\n",
    "        if space_count > words_per_line - 1:\n",
    "            result.append(t[start:end])\n",
    "            start = end + 1\n",
    "            space_count = 0\n",
    "        if i == len(t) - 1:\n",
    "            result.append(t[start: end + 1])\n",
    "        if len(result) == num_lines:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day,\n",
      "thou art more lovely apry death's better sight.\n",
      "sees beautious not so should look in at,\n",
      "me so ilike of you to be and.\n",
      "do i foul that your self alone the,\n",
      "is but since his now so ruch as.\n",
      "end i gain and pleased my love be,\n",
      "forgettent her o better dost and all blink.\n",
      "name but now to fear as blinh so,\n",
      "defence the fairest grow and so rellyer stell.\n"
     ]
    }
   ],
   "source": [
    "poem = get_poem(result, 8, 10)\n",
    "for i in range(len(poem)):\n",
    "    if i % 2 == 0:\n",
    "        print(poem[i] + ',')\n",
    "    else:\n",
    "        print(poem[i] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
