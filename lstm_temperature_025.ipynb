{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Lambda\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84692\n"
     ]
    }
   ],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "all_text = open(\"data/shakespeare.txt\").read().lower()\n",
    "all_text = ''.join([i for i in all_text if not i.isdigit()])\n",
    "SYMBOL_LIST = {'?', '.',  ')', ',', '!', ';', '(', ':'}\n",
    "sonnets = all_text.replace('                   ', '').split('\\n\\n\\n')\n",
    "sonnets = [sonnet[1:] for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('\\n', ' ') for sonnet in sonnets]\n",
    "sonnets = [sonnet.replace('  ', '') for sonnet in sonnets]\n",
    "sonnets = [''.join([i for i in sonnet if not i in SYMBOL_LIST]) for sonnet in sonnets]\n",
    "\n",
    "all_chars = sorted(list(set(''.join(sonnets))))\n",
    "max_char = len(all_chars) - 1\n",
    "char_map = {}\n",
    "int_to_char = {}\n",
    "int_to_arr = {}\n",
    "for i in range(len(all_chars)):\n",
    "    char_map[all_chars[i]] = i\n",
    "    int_to_char[i] = all_chars[i]\n",
    "    arr = [0] * len(all_chars) \n",
    "    arr[i] = 1\n",
    "    int_to_arr[i] = arr\n",
    "\n",
    "# print(sonnets)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for sonnet in sonnets:\n",
    "    start = 0\n",
    "    end = 40\n",
    "    while end < len(sonnet):\n",
    "        sequence = sonnet[start:end]\n",
    "        X_train.append([(char_map[c]) for c in sequence])\n",
    "        Y_train.append(char_map[sonnet[end]])\n",
    "        start += 1\n",
    "        end += 1\n",
    "        \n",
    "samples = len(X_train)\n",
    "timesteps = 40\n",
    "features = len(all_chars)\n",
    "X_train = [[int_to_arr[x] for x in seq] for seq in X_train]\n",
    "\n",
    "X_train = np.array(X_train) \n",
    "X_train = np.reshape(X_train, (samples, timesteps, features))\n",
    "Y_train = np.array([int_to_arr[y] for y in Y_train])\n",
    "\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84692/84692 [==============================] - 376s 4ms/step - loss: 2.3525\n",
      "Epoch 2/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.9239\n",
      "Epoch 3/50\n",
      "84692/84692 [==============================] - 369s 4ms/step - loss: 1.7821\n",
      "Epoch 4/50\n",
      "84692/84692 [==============================] - 368s 4ms/step - loss: 1.6929\n",
      "Epoch 5/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.6232\n",
      "Epoch 6/50\n",
      "84692/84692 [==============================] - 364s 4ms/step - loss: 1.5637\n",
      "Epoch 7/50\n",
      "84692/84692 [==============================] - 364s 4ms/step - loss: 1.5115\n",
      "Epoch 8/50\n",
      "84692/84692 [==============================] - 364s 4ms/step - loss: 1.4638\n",
      "Epoch 9/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.4190\n",
      "Epoch 10/50\n",
      "84692/84692 [==============================] - 368s 4ms/step - loss: 1.3770\n",
      "Epoch 11/50\n",
      "84692/84692 [==============================] - 364s 4ms/step - loss: 1.3317\n",
      "Epoch 12/50\n",
      "84692/84692 [==============================] - 363s 4ms/step - loss: 1.2876\n",
      "Epoch 13/50\n",
      "84692/84692 [==============================] - 364s 4ms/step - loss: 1.2450\n",
      "Epoch 14/50\n",
      "84692/84692 [==============================] - 370s 4ms/step - loss: 1.2031\n",
      "Epoch 15/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.1589\n",
      "Epoch 16/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.1126\n",
      "Epoch 17/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.0721\n",
      "Epoch 18/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 1.0316\n",
      "Epoch 19/50\n",
      "84692/84692 [==============================] - 367s 4ms/step - loss: 0.9907\n",
      "Epoch 20/50\n",
      "84692/84692 [==============================] - 372s 4ms/step - loss: 0.9502\n",
      "Epoch 21/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 0.9111\n",
      "Epoch 22/50\n",
      "84692/84692 [==============================] - 365s 4ms/step - loss: 0.8734\n",
      "Epoch 23/50\n",
      "84692/84692 [==============================] - 370s 4ms/step - loss: 0.8426\n",
      "Epoch 24/50\n",
      "84692/84692 [==============================] - 404s 5ms/step - loss: 0.8067\n",
      "Epoch 25/50\n",
      "84692/84692 [==============================] - 400s 5ms/step - loss: 0.7788\n",
      "Epoch 26/50\n",
      "84692/84692 [==============================] - 426s 5ms/step - loss: 0.7493\n",
      "Epoch 27/50\n",
      "84692/84692 [==============================] - 539s 6ms/step - loss: 0.7238\n",
      "Epoch 28/50\n",
      "84692/84692 [==============================] - 535s 6ms/step - loss: 0.6962\n",
      "Epoch 29/50\n",
      "84692/84692 [==============================] - 527s 6ms/step - loss: 0.6756\n",
      "Epoch 30/50\n",
      "84692/84692 [==============================] - 527s 6ms/step - loss: 0.6512\n",
      "Epoch 31/50\n",
      "84692/84692 [==============================] - 542s 6ms/step - loss: 0.6334\n",
      "Epoch 32/50\n",
      "84692/84692 [==============================] - 534s 6ms/step - loss: 0.6148\n",
      "Epoch 33/50\n",
      "84692/84692 [==============================] - 533s 6ms/step - loss: 0.5982\n",
      "Epoch 34/50\n",
      "84692/84692 [==============================] - 536s 6ms/step - loss: 0.5793\n",
      "Epoch 35/50\n",
      "84692/84692 [==============================] - 549s 6ms/step - loss: 0.5663\n",
      "Epoch 36/50\n",
      "84692/84692 [==============================] - 543s 6ms/step - loss: 0.5514\n",
      "Epoch 37/50\n",
      "84692/84692 [==============================] - 542s 6ms/step - loss: 0.5338\n",
      "Epoch 38/50\n",
      "84692/84692 [==============================] - 547s 6ms/step - loss: 0.5223\n",
      "Epoch 39/50\n",
      "84692/84692 [==============================] - 550s 6ms/step - loss: 0.5130\n",
      "Epoch 40/50\n",
      "84692/84692 [==============================] - 555s 7ms/step - loss: 0.4962\n",
      "Epoch 41/50\n",
      "84692/84692 [==============================] - 576s 7ms/step - loss: 0.4881\n",
      "Epoch 42/50\n",
      "84692/84692 [==============================] - 562s 7ms/step - loss: 0.4774\n",
      "Epoch 43/50\n",
      "84692/84692 [==============================] - 549s 6ms/step - loss: 0.4713\n",
      "Epoch 44/50\n",
      "84692/84692 [==============================] - 583s 7ms/step - loss: 0.4583\n",
      "Epoch 45/50\n",
      "84692/84692 [==============================] - 613s 7ms/step - loss: 0.4544\n",
      "Epoch 46/50\n",
      "84692/84692 [==============================] - 553s 7ms/step - loss: 0.4437\n",
      "Epoch 47/50\n",
      "84692/84692 [==============================] - 558s 7ms/step - loss: 0.4324\n",
      "Epoch 48/50\n",
      "84692/84692 [==============================] - 524s 6ms/step - loss: 0.4296\n",
      "Epoch 49/50\n",
      "84692/84692 [==============================] - 467s 6ms/step - loss: 0.4157\n",
      "Epoch 50/50\n",
      "84692/84692 [==============================] - 487s 6ms/step - loss: 0.4103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115a8bf28>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Layers:\n",
    "temp = 0.25\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(timesteps, features), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Lambda(lambda x: x / temp))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=128)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day thou hast before decay which have no prouded confound are you worse when it hath in my life doth live thou usure in thy beauty's form in un of the laining sweets and death and statute of me for thou not farther frame that thou mayst true love contain and beauty looking on darks are men your sight and praise deceared this toe on thee and ghat's in heaven's sun at pution blunk dis rink to each that virtue o all the time contorded from the fairest rove is think all in in makes gracious in me but which full brow if thou should fasther frame for did chance write show my self will be this leave which i behold the lique and kind of present and do the wind whilst thou canst not to be a secold flowers in odour quick for i have now wend he way to that you so for my soul and ap is hide my moan then lost steal stay of love i think on thee when i am black any beauty's salse 'tis the wising he of a tropthere is by but of to that afford no eceive thy body's true making sins you will i  ay but thou may\n"
     ]
    }
   ],
   "source": [
    "def next_char(input_str, m):\n",
    "    X_in = np.array([[int_to_arr[char_map[c]] for c in input_str]])\n",
    "    [probs] = m.predict(X_in, verbose=0)\n",
    "    options = list(range(len(probs)))\n",
    "\n",
    "    \n",
    "    prediction = np.random.choice(options,p =  probs)\n",
    "    \n",
    "    return int_to_char[prediction]\n",
    "\n",
    "result = \"shall i compare thee to a summer's day t\"\n",
    "window = \"shall i compare thee to a summer's day t\"\n",
    "for i in range(1000):\n",
    "    prediction = next_char(window, model)\n",
    "    result = result + prediction\n",
    "    window = window[1:] + prediction\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poem(t, words_per_line, num_lines):\n",
    "    result = []\n",
    "\n",
    "    start = 0\n",
    "    end = -1\n",
    "    space_count = 0\n",
    "\n",
    "    for i in range(len(t)):\n",
    "        end += 1\n",
    "        if t[i] == ' ':\n",
    "            space_count += 1\n",
    "        if space_count > words_per_line - 1:\n",
    "            result.append(t[start:end])\n",
    "            start = end + 1\n",
    "            space_count = 0\n",
    "        if i == len(t) - 1:\n",
    "            result.append(t[start: end + 1])\n",
    "        if len(result) == num_lines:\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day,\n",
      "thou hast before decay which have no prouded.\n",
      "confound are you worse when it hath in,\n",
      "my life doth live thou usure in thy.\n",
      "beauty's form in un of the laining sweets,\n",
      "and death and statute of me for thou.\n",
      "not farther frame that thou mayst true love,\n",
      "contain and beauty looking on darks are men.\n",
      "your sight and praise deceared this toe on,\n",
      "thee and ghat's in heaven's sun at pution.\n"
     ]
    }
   ],
   "source": [
    "poem = get_poem(result, 8, 10)\n",
    "for i in range(len(poem)):\n",
    "    if i % 2 == 0:\n",
    "        print(poem[i] + ',')\n",
    "    else:\n",
    "        print(poem[i] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
